# Dl

CNN

LeNet

![image-20220916144909654](D:%5CTyporaPic%5Cimage-20220916144909654.png)

IMageNet

VGGNet

![image-20220916145135009](D:%5CTyporaPic%5Cimage-20220916145135009.png)

Google Net

![image-20220916145153968](D:%5CTyporaPic%5Cimage-20220916145153968.png)

![image-20220916145604336](D:%5CTyporaPic%5Cimage-20220916145604336.png)

![image-20220927104643961](深度学习.assets/image-20220927104643961.png)

![image-20221002194234256](深度学习.assets/image-20221002194234256.png)

![image-20221002194450977](深度学习.assets/image-20221002194450977.png)



## MP模型

![image-20221002212148807](深度学习.assets/image-20221002212148807.png)

MP模型的权值w和偏置b都是认为给定的， 所以此模型不存在学习的说法

## 感知机

![image-20221002212230775](深度学习.assets/image-20221002212230775.png)

**感知机与MP模型的区别**

- 输入可以不是离散型
- 激活函数可以不再是简单的阈值函数

单层感知机引入了损失函数， 

多层感知机通过增加层数解决非线性问题， 但是需要人为固定一层参数，只能训练其中一层。

## 前馈神经网络



## CNN

卷积神经网络

## RNN

### 循环神经网络

![image-20221003113538163](深度学习.assets/image-20221003113538163.png)

 ![image-20221003113915549](深度学习.assets/image-20221003113915549.png)

![image-20221003113929040](深度学习.assets/image-20221003113929040.png)

![image-20221003114051533](深度学习.assets/image-20221003114051533.png)

![image-20221003141234990](深度学习.assets/image-20221003141234990.png)

![image-20221003145040232](深度学习.assets/image-20221003145040232.png)

![image-20221003145152023](深度学习.assets/image-20221003145152023.png)

![image-20221003153907521](深度学习.assets/image-20221003153907521.png)



双曲正切函数

![image-20221003141421778](深度学习.assets/image-20221003141421778.png)

![image-20221003141504476](深度学习.assets/image-20221003141504476.png)



当x 很大时 ， 曲线趋于平行，梯度为零，产生梯度消失。

https://mp.weixin.qq.com/s/mLic_aC0FgCVAIP4lYh7Dw 

**递归神经网络**

二者都可以处理有序列的问题



为了加强记忆能力，提出了LSTM

### 长短期记忆网络LSTM （long short -term Memory）   

解决长期及远距离的依赖关系     数据之间存在前后依赖关系， 有序列关系

如果预测对象同时取决于过去和未来，可以选择双向结构， 如双向LSTM

![image-20221003150303386](深度学习.assets/image-20221003150303386.png)



![image-20221003160431821](深度学习.assets/image-20221003160431821.png)

![image-20221003160456955](深度学习.assets/image-20221003160456955.png)

![image-20221003160510727](深度学习.assets/image-20221003160510727.png)

![image-20221003160518194](深度学习.assets/image-20221003160518194.png)



![image-20221003161551280](深度学习.assets/image-20221003161551280.png)

![image-20221003161654912](深度学习.assets/image-20221003161654912.png)

![image-20221003170002412](深度学习.assets/image-20221003170002412.png)

![image-20221003170015576](深度学习.assets/image-20221003170015576.png)



![image-20221003170108112](深度学习.assets/image-20221003170108112.png)

![image-20221003170223131](深度学习.assets/image-20221003170223131.png)



ft 遗忘门

![image-20221003173857803](深度学习.assets/image-20221003173857803.png)

it 更新门

过滤新状态 无关特征量   产生新的记忆内容 

![image-20221003174522022](深度学习.assets/image-20221003174522022.png)+![image-20221003174530749](深度学习.assets/image-20221003174530749.png)

![image-20221003174605015](深度学习.assets/image-20221003174605015.png)

ot输出门

![image-20221003171430317](深度学习.assets/image-20221003171430317.png)

![image-20221003172101576](深度学习.assets/image-20221003172101576.png)

![image-20221003172224872](深度学习.assets/image-20221003172224872.png)



![image-20221003174636795](深度学习.assets/image-20221003174636795.png)

tan h提取当前记忆中需要的部分 输出为Ht

相关视频 

https://www.bilibili.com/video/BV1qM4y1M7Nv?p=4&spm_id_from=pageDriver&vd_source=33d4f5ace56eb158f8b3252ac671ebfe





## 门控循环[神经网络](https://so.csdn.net/so/search?q=神经网络&spm=1001.2101.3001.7020)（gated recurrent neural network）

## 深度信念网络DBN

主要有两个部分: 

1. 堆叠的受限玻尔兹曼机(Stacked RBM)
2. 一层普通的前馈网络。

DBN最主要的特色可以理解为两阶段学习，

- 阶段1用堆叠的RBM通过无监督学习进行预训练(Pre-train)，
- 阶段2用普通的前馈网络进行微调。



















神经网络的精髓就是进行特征提取  















## 径向基网络(Radial Basis Network (RBN)) 

## 深度前馈(Deep Feed-forward (DFF)) 

## 生成式对抗网络 GAN

解决了非监督学习中的著名问题，给定一批样本训练一个系统， 能够生成类似的样本

**生成模型**

生成方法和判别方法， 

生成方法通过观测数据学习样本与标签的联合概率分布（X，Y）训练好的模型能够生成符合样本分布的新数据，它可以用于有监督 和 无监督学习，

生成模型是指我们可以根据任务，通过模型训练由输入的数据生成文字， 图像，视频等教程。

本质上是一种极大似然估计， 用于产生指定分布数据的模型，生成模型的作用是捕捉样本数据的分布， 将原输入信息的分布情况经过极大似然估计中参数的转化来讲训练偏向转换为指定分布的样本。



**判别模型**  实际上是一个二分类， 会对生成模型生成的图像等数据进行判断， 判断其是否是真实的训练数据中的数据。





判别方法 由数据直接学习决策函数或这条件概率分布作为预测的模型

![image-20221003084444547](深度学习.assets/image-20221003084444547.png)

有生成器和判别器组成，

生成器生成满足目标分布映射关系的新样本，

判别器用来区别实际数据分布和生成器产生的数据分布

![image-20221003084815407](深度学习.assets/image-20221003084815407.png)

![image-20221003090053293](深度学习.assets/image-20221003090053293.png)



![image-20221003090344963](深度学习.assets/image-20221003090344963.png)

 ![image-20221003090620270](深度学习.assets/image-20221003090620270.png)

![image-20221003090925447](深度学习.assets/image-20221003090925447.png)

![image-20221003094522893](深度学习.assets/image-20221003094522893.png)

![image-20221003102824781](深度学习.assets/image-20221003102824781.png)

![image-20221003102257044](深度学习.assets/image-20221003102257044.png)



定义损失函数  固定生成器或者判别器中的一个 调整另一个中的参数

GAN固定一个 另一个无法升级  梯度消失

![image-20221003091157791](深度学习.assets/image-20221003091157791.png)



## 自动编码器 Auto-encoder

![image-20221003111007788](深度学习.assets/image-20221003111007788.png)

、![image-20221003111648934](深度学习.assets/image-20221003111648934.png)

![image-20221003112128815](深度学习.assets/image-20221003112128815.png)





## 变分自动编码器(Variational Autoencoder (VAE)) 





## 去噪自动编码器(Denoising Autoencoder (DAE) 

## 稀疏自动编码器(Sparse Autoencoder (SAE)) 



## attention机制



 

## 前向传播算法与反向传播算法

https://zhuanlan.zhihu.com/p/71892752

## 反卷积神经网络(Deconvolutional Neural Networks (DN))

## 深度卷积网络(Deep Convolutional Network (DCN)) 

## 波茨曼机(Boltzmann Machine (BM)):

## 受限玻尔兹曼机(Restricted Boltzmann Machine (RBM))

## 霍菲特网络(Hopfield Network (HN)):

## 深度卷积逆图形网络(Deep Convolutional Inverse Graphics Network (DC-IGN)) 

## 深度残差网络(Deep Residual Network (DRN)) 

## Kohonen网络(Kohonen Networks (KN) )

## 支持向量机(Support Vector Machines (SVM)):

## 神经图灵机(Neural Turing Machine (NTM))

## 回声状态网络(Echo State Network (ESN)) 

## 自回归网络

## 注意力机制

![image-20221003184617655](深度学习.assets/image-20221003184617655.png)



![image-20221003184724985](深度学习.assets/image-20221003184724985.png)

![image-20221003185528113](深度学习.assets/image-20221003185528113.png)

**给予不同的项一定的比重，比重越大越聚焦于其对应的value值上， 即权重代表了信息的重要性，而value是其对应的信息。**

**从大量信息中有选择的筛选出 少量重要信息，并且聚焦到这些重要信息中，忽略大多不重要的信息。**

![image-20221003190026894](深度学习.assets/image-20221003190026894.png)

本质上都是分而治之的思想。



### 具体的计算机制

![image-20221003190238805](深度学习.assets/image-20221003190238805.png)



![image-20221003190403384](深度学习.assets/image-20221003190403384.png)

  ![image-20221003192812557](深度学习.assets/image-20221003192812557.png)

**SELF Attention**



## PNN模型

![image-20221003202807877](深度学习.assets/image-20221003202807877.png)

 ![image-20221003203048387](深度学习.assets/image-20221003203048387.png)













